{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e8489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import epoch_based_evolution as ebe\n",
    "import load_data as ld # for loading and transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa39cd7",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc76447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features detected: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V44', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V57', 'V58', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V128', 'V129', 'V130', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144']\n",
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! Format: tensor\n",
      "Training data shape: torch.Size([1909, 280])\n"
     ]
    }
   ],
   "source": [
    "DATA_ID = 41143\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = ld.get_preprocessed_data(\n",
    "        dataset_id=DATA_ID, scaling=True, random_seed=13, return_as='tensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501cba7",
   "metadata": {},
   "source": [
    "# EBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21420aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input and output sizes are needed for the model, these are integers\n",
    "input_size, output_size = ld.get_tensor_sizes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a44bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The search space for the architectures is defined here, \n",
    "# possible arguments can be modified, check the class definition\n",
    "\n",
    "search_space = ebe.SearchSpace(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c67cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INDIVIDUALS = 100 # amount of architectures to be evaluated as a starting point\n",
    "N_EPOCHS = 5 \n",
    "percentile_drop = 25 # drop the worst 25% of architectures after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f27335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generation is created given the search space and the number of individuals.\n",
    "generation = ebe.Generation(search_space, N_INDIVIDUALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb16863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "generation.run_ebe(n_epochs=N_EPOCHS,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_val=X_val,\n",
    "                    y_val=y_val, percentile_drop=percentile_drop)\n",
    "\n",
    "results_df = generation.return_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1545ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation_fn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dropout_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "optimizer_type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "batch_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "use_skip_connections",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "initializer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lr_scheduler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scheduler_params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "706fdfc9-4d77-42c0-b7a2-fa2f8b536023",
       "rows": [
        [
         "0",
         "[70, 415, 111, 372, 345]",
         "<class 'torch.nn.modules.activation.GELU'>",
         "0.1",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.006821674427478449",
         "1e-05",
         null,
         "32",
         "True",
         "kaiming_uniform",
         "step",
         "{'step_size': 30, 'gamma': 0.1}",
         "0.4207008629334791",
         "0.8046097433211106",
         "0.4427238422208251",
         "0.7761506276150628"
        ],
        [
         "1",
         "[489, 193, 342, 34]",
         "<class 'torch.nn.modules.activation.GELU'>",
         "0.1",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.00029980635691626386",
         "0.01",
         null,
         "256",
         "True",
         "kaiming_uniform",
         "none",
         "{}",
         "0.4080365655652012",
         "0.8088004190675746",
         "0.4430334765043219",
         "0.7698744769874477"
        ],
        [
         "2",
         "[435, 105, 437, 305, 487, 497, 464]",
         "<class 'torch.nn.modules.activation.GELU'>",
         "0.2",
         "<class 'torch.optim.rmsprop.RMSprop'>",
         "0.0028104251216825274",
         "1e-06",
         null,
         "128",
         "False",
         "xavier_normal",
         "none",
         "{}",
         "0.49045516114199955",
         "0.7537977998952331",
         "0.45837690590814567",
         "0.7677824267782427"
        ],
        [
         "3",
         "[105, 375, 410, 417, 62]",
         "<class 'torch.nn.modules.activation.GELU'>",
         "0.2",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.0004528134453872139",
         "1e-06",
         null,
         "128",
         "True",
         "kaiming_normal",
         "step",
         "{'step_size': 30, 'gamma': 0.1}",
         "0.45205248385714636",
         "0.7799895233106339",
         "0.44304460112519845",
         "0.7656903765690377"
        ],
        [
         "4",
         "[187, 14, 21, 152, 128, 100, 97]",
         "<class 'torch.nn.modules.activation.ELU'>",
         "0.0",
         "<class 'torch.optim.adam.Adam'>",
         "0.0017514667031217981",
         "0.01",
         null,
         "1024",
         "True",
         "xavier_normal",
         "none",
         "{}",
         "0.41303304861889517",
         "0.8014667365112624",
         "0.4557742178440094",
         "0.7656903765690377"
        ],
        [
         "5",
         "[172, 402, 455, 266]",
         "<class 'torch.nn.modules.activation.LeakyReLU'>",
         "0.5",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.00860689478653942",
         "0.01",
         null,
         "256",
         "True",
         "kaiming_normal",
         "cosine",
         "{'T_max': 50}",
         "0.4592907305879078",
         "0.7784180199057098",
         "0.44776509858075547",
         "0.7615062761506276"
        ],
        [
         "6",
         "[137, 214, 461, 383, 340, 427]",
         "<class 'torch.nn.modules.activation.ReLU'>",
         "0.3",
         "<class 'torch.optim.adam.Adam'>",
         "0.0008604246668699407",
         "0.001",
         null,
         "32",
         "True",
         "kaiming_uniform",
         "step",
         "{'step_size': 30, 'gamma': 0.9}",
         "0.4501670104646133",
         "0.7888947092718701",
         "0.4459858317255475",
         "0.7594142259414226"
        ],
        [
         "7",
         "[65, 123, 37]",
         "<class 'torch.nn.modules.activation.ELU'>",
         "0.3",
         "<class 'torch.optim.adam.Adam'>",
         "0.029567711366831687",
         "0.0001",
         null,
         "128",
         "True",
         "xavier_normal",
         "cosine",
         "{'T_max': 10}",
         "0.458198983423244",
         "0.7841801990570979",
         "0.45545386220620765",
         "0.7594142259414226"
        ],
        [
         "8",
         "[341, 99, 106, 21]",
         "<class 'torch.nn.modules.activation.ReLU'>",
         "0.2",
         "<class 'torch.optim.rmsprop.RMSprop'>",
         "0.0025279100624861954",
         "0.01",
         null,
         "256",
         "True",
         "kaiming_uniform",
         "cosine",
         "{'T_max': 100}",
         "0.4170768830462736",
         "0.8072289156626506",
         "0.46243320636170676",
         "0.7573221757322176"
        ],
        [
         "9",
         "[261, 252, 214]",
         "<class 'torch.nn.modules.activation.LeakyReLU'>",
         "0.3",
         "<class 'torch.optim.rmsprop.RMSprop'>",
         "0.00662419775774725",
         "0.01",
         null,
         "64",
         "False",
         "xavier_uniform",
         "none",
         "{}",
         "0.4530614163939275",
         "0.7805133577789418",
         "0.46488558348252684",
         "0.7552301255230126"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation_fn</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>use_skip_connections</th>\n",
       "      <th>initializer</th>\n",
       "      <th>lr_scheduler</th>\n",
       "      <th>scheduler_params</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[70, 415, 111, 372, 345]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.GELU'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 30, 'gamma': 0.1}</td>\n",
       "      <td>0.420701</td>\n",
       "      <td>0.804610</td>\n",
       "      <td>0.442724</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[489, 193, 342, 34]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.GELU'&gt;</td>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.408037</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.443033</td>\n",
       "      <td>0.769874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[435, 105, 437, 305, 487, 497, 464]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.GELU'&gt;</td>\n",
       "      <td>0.2</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.490455</td>\n",
       "      <td>0.753798</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>0.767782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[105, 375, 410, 417, 62]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.GELU'&gt;</td>\n",
       "      <td>0.2</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 30, 'gamma': 0.1}</td>\n",
       "      <td>0.452052</td>\n",
       "      <td>0.779990</td>\n",
       "      <td>0.443045</td>\n",
       "      <td>0.765690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[187, 14, 21, 152, 128, 100, 97]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ELU'&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024</td>\n",
       "      <td>True</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.413033</td>\n",
       "      <td>0.801467</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.765690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[172, 402, 455, 266]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.LeakyReLU'&gt;</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 50}</td>\n",
       "      <td>0.459291</td>\n",
       "      <td>0.778418</td>\n",
       "      <td>0.447765</td>\n",
       "      <td>0.761506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[137, 214, 461, 383, 340, 427]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ReLU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 30, 'gamma': 0.9}</td>\n",
       "      <td>0.450167</td>\n",
       "      <td>0.788895</td>\n",
       "      <td>0.445986</td>\n",
       "      <td>0.759414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[65, 123, 37]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ELU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.029568</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 10}</td>\n",
       "      <td>0.458199</td>\n",
       "      <td>0.784180</td>\n",
       "      <td>0.455454</td>\n",
       "      <td>0.759414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[341, 99, 106, 21]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ReLU'&gt;</td>\n",
       "      <td>0.2</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 100}</td>\n",
       "      <td>0.417077</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.462433</td>\n",
       "      <td>0.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[261, 252, 214]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.LeakyReLU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.453061</td>\n",
       "      <td>0.780513</td>\n",
       "      <td>0.464886</td>\n",
       "      <td>0.755230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hidden_layers  \\\n",
       "0             [70, 415, 111, 372, 345]   \n",
       "1                  [489, 193, 342, 34]   \n",
       "2  [435, 105, 437, 305, 487, 497, 464]   \n",
       "3             [105, 375, 410, 417, 62]   \n",
       "4     [187, 14, 21, 152, 128, 100, 97]   \n",
       "5                 [172, 402, 455, 266]   \n",
       "6       [137, 214, 461, 383, 340, 427]   \n",
       "7                        [65, 123, 37]   \n",
       "8                   [341, 99, 106, 21]   \n",
       "9                      [261, 252, 214]   \n",
       "\n",
       "                                     activation_fn  dropout_rate  \\\n",
       "0       <class 'torch.nn.modules.activation.GELU'>           0.1   \n",
       "1       <class 'torch.nn.modules.activation.GELU'>           0.1   \n",
       "2       <class 'torch.nn.modules.activation.GELU'>           0.2   \n",
       "3       <class 'torch.nn.modules.activation.GELU'>           0.2   \n",
       "4        <class 'torch.nn.modules.activation.ELU'>           0.0   \n",
       "5  <class 'torch.nn.modules.activation.LeakyReLU'>           0.5   \n",
       "6       <class 'torch.nn.modules.activation.ReLU'>           0.3   \n",
       "7        <class 'torch.nn.modules.activation.ELU'>           0.3   \n",
       "8       <class 'torch.nn.modules.activation.ReLU'>           0.2   \n",
       "9  <class 'torch.nn.modules.activation.LeakyReLU'>           0.3   \n",
       "\n",
       "                          optimizer_type  learning_rate  weight_decay  \\\n",
       "0      <class 'torch.optim.adamw.AdamW'>       0.006822      0.000010   \n",
       "1      <class 'torch.optim.adamw.AdamW'>       0.000300      0.010000   \n",
       "2  <class 'torch.optim.rmsprop.RMSprop'>       0.002810      0.000001   \n",
       "3      <class 'torch.optim.adamw.AdamW'>       0.000453      0.000001   \n",
       "4        <class 'torch.optim.adam.Adam'>       0.001751      0.010000   \n",
       "5      <class 'torch.optim.adamw.AdamW'>       0.008607      0.010000   \n",
       "6        <class 'torch.optim.adam.Adam'>       0.000860      0.001000   \n",
       "7        <class 'torch.optim.adam.Adam'>       0.029568      0.000100   \n",
       "8  <class 'torch.optim.rmsprop.RMSprop'>       0.002528      0.010000   \n",
       "9  <class 'torch.optim.rmsprop.RMSprop'>       0.006624      0.010000   \n",
       "\n",
       "   momentum  batch_size  use_skip_connections      initializer lr_scheduler  \\\n",
       "0       NaN          32                  True  kaiming_uniform         step   \n",
       "1       NaN         256                  True  kaiming_uniform         none   \n",
       "2       NaN         128                 False    xavier_normal         none   \n",
       "3       NaN         128                  True   kaiming_normal         step   \n",
       "4       NaN        1024                  True    xavier_normal         none   \n",
       "5       NaN         256                  True   kaiming_normal       cosine   \n",
       "6       NaN          32                  True  kaiming_uniform         step   \n",
       "7       NaN         128                  True    xavier_normal       cosine   \n",
       "8       NaN         256                  True  kaiming_uniform       cosine   \n",
       "9       NaN          64                 False   xavier_uniform         none   \n",
       "\n",
       "                  scheduler_params  train_loss  train_acc  val_loss   val_acc  \n",
       "0  {'step_size': 30, 'gamma': 0.1}    0.420701   0.804610  0.442724  0.776151  \n",
       "1                               {}    0.408037   0.808800  0.443033  0.769874  \n",
       "2                               {}    0.490455   0.753798  0.458377  0.767782  \n",
       "3  {'step_size': 30, 'gamma': 0.1}    0.452052   0.779990  0.443045  0.765690  \n",
       "4                               {}    0.413033   0.801467  0.455774  0.765690  \n",
       "5                    {'T_max': 50}    0.459291   0.778418  0.447765  0.761506  \n",
       "6  {'step_size': 30, 'gamma': 0.9}    0.450167   0.788895  0.445986  0.759414  \n",
       "7                    {'T_max': 10}    0.458199   0.784180  0.455454  0.759414  \n",
       "8                   {'T_max': 100}    0.417077   0.807229  0.462433  0.757322  \n",
       "9                               {}    0.453061   0.780513  0.464886  0.755230  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4220afb",
   "metadata": {},
   "source": [
    "# Train N top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a98802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ebe.create_model_from_row(results_df.iloc[0], \n",
    "                                  input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e99c1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # batch size for training the model\n",
    "# For training a model, DataLoader is needed\n",
    "train_loader = ebe.create_dataloaders(X=X_train, y=y_train, \n",
    "                       batch_size=batch_size)\n",
    "val_loader = ebe.create_dataloaders(X=X_val, y=y_val, \n",
    "                       batch_size=batch_size)\n",
    "test_loader = ebe.create_dataloaders(X=X_test, y=y_test, \n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "557c196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc found: 0.7510460251046025\n",
      "Epoch 1: Train Loss=0.4751, Train Acc=0.7643, Val Loss=0.4627, Val Acc=0.7510\n",
      "Epoch 2: Train Loss=0.4159, Train Acc=0.8062, Val Loss=0.4671, Val Acc=0.7448\n",
      "New best acc found: 0.7531380753138075\n",
      "Epoch 3: Train Loss=0.3699, Train Acc=0.8303, Val Loss=0.4920, Val Acc=0.7531\n",
      "New best acc found: 0.7573221757322176\n",
      "Epoch 4: Train Loss=0.3273, Train Acc=0.8617, Val Loss=0.4897, Val Acc=0.7573\n",
      "Epoch 5: Train Loss=0.2745, Train Acc=0.8937, Val Loss=0.5846, Val Acc=0.7490\n",
      "Epoch 6: Train Loss=0.2396, Train Acc=0.8910, Val Loss=0.6755, Val Acc=0.7134\n",
      "Epoch 7: Train Loss=0.2109, Train Acc=0.9162, Val Loss=0.6460, Val Acc=0.7469\n",
      "New best acc found: 0.7594142259414226\n",
      "Epoch 8: Train Loss=0.1654, Train Acc=0.9314, Val Loss=0.7804, Val Acc=0.7594\n",
      "Epoch 9: Train Loss=0.1278, Train Acc=0.9455, Val Loss=0.8703, Val Acc=0.7469\n",
      "Epoch 10: Train Loss=0.1330, Train Acc=0.9471, Val Loss=0.8067, Val Acc=0.7406\n",
      "Epoch 11: Train Loss=0.1002, Train Acc=0.9612, Val Loss=0.9279, Val Acc=0.7469\n",
      "New best acc found: 0.7887029288702929\n",
      "Epoch 12: Train Loss=0.0963, Train Acc=0.9633, Val Loss=0.9450, Val Acc=0.7887\n",
      "Epoch 13: Train Loss=0.0665, Train Acc=0.9754, Val Loss=1.0788, Val Acc=0.7741\n",
      "Epoch 14: Train Loss=0.0636, Train Acc=0.9728, Val Loss=1.1187, Val Acc=0.7636\n",
      "Epoch 15: Train Loss=0.0649, Train Acc=0.9738, Val Loss=1.1500, Val Acc=0.7448\n",
      "Epoch 16: Train Loss=0.0811, Train Acc=0.9670, Val Loss=1.0132, Val Acc=0.7615\n",
      "Epoch 17: Train Loss=0.0568, Train Acc=0.9811, Val Loss=1.2680, Val Acc=0.7594\n",
      "Epoch 18: Train Loss=0.0523, Train Acc=0.9822, Val Loss=1.2070, Val Acc=0.7469\n",
      "Epoch 19: Train Loss=0.0489, Train Acc=0.9796, Val Loss=1.3031, Val Acc=0.7343\n",
      "Epoch 20: Train Loss=0.0455, Train Acc=0.9827, Val Loss=1.3262, Val Acc=0.7427\n",
      "Epoch 21: Train Loss=0.0352, Train Acc=0.9880, Val Loss=1.3180, Val Acc=0.7657\n",
      "Epoch 22: Train Loss=0.0314, Train Acc=0.9900, Val Loss=1.3644, Val Acc=0.7762\n",
      "Epoch 23: Train Loss=0.0421, Train Acc=0.9843, Val Loss=1.2966, Val Acc=0.7762\n",
      "Epoch 24: Train Loss=0.0425, Train Acc=0.9848, Val Loss=1.2686, Val Acc=0.7469\n",
      "Epoch 25: Train Loss=0.0382, Train Acc=0.9864, Val Loss=1.3027, Val Acc=0.7322\n",
      "Epoch 26: Train Loss=0.0276, Train Acc=0.9900, Val Loss=1.4189, Val Acc=0.7343\n",
      "Epoch 27: Train Loss=0.0438, Train Acc=0.9874, Val Loss=1.3625, Val Acc=0.7531\n",
      "Epoch 28: Train Loss=0.0264, Train Acc=0.9890, Val Loss=1.4459, Val Acc=0.7552\n",
      "Epoch 29: Train Loss=0.0378, Train Acc=0.9880, Val Loss=1.3601, Val Acc=0.7510\n",
      "Epoch 30: Train Loss=0.0364, Train Acc=0.9890, Val Loss=1.2812, Val Acc=0.7720\n",
      "Epoch 31: Train Loss=0.0312, Train Acc=0.9890, Val Loss=1.2130, Val Acc=0.7762\n",
      "Epoch 32: Train Loss=0.0234, Train Acc=0.9927, Val Loss=1.3585, Val Acc=0.7720\n",
      "Epoch 33: Train Loss=0.0224, Train Acc=0.9916, Val Loss=1.4713, Val Acc=0.7636\n",
      "Epoch 34: Train Loss=0.0302, Train Acc=0.9895, Val Loss=1.4080, Val Acc=0.7469\n",
      "Epoch 35: Train Loss=0.0174, Train Acc=0.9916, Val Loss=1.5377, Val Acc=0.7531\n",
      "Epoch 36: Train Loss=0.0346, Train Acc=0.9900, Val Loss=1.4508, Val Acc=0.7490\n",
      "Epoch 37: Train Loss=0.0422, Train Acc=0.9848, Val Loss=1.1869, Val Acc=0.7594\n",
      "Epoch 38: Train Loss=0.0348, Train Acc=0.9890, Val Loss=1.3485, Val Acc=0.7531\n",
      "Epoch 39: Train Loss=0.0163, Train Acc=0.9953, Val Loss=1.5178, Val Acc=0.7552\n",
      "Epoch 40: Train Loss=0.0307, Train Acc=0.9900, Val Loss=1.3604, Val Acc=0.7490\n",
      "Epoch 41: Train Loss=0.0239, Train Acc=0.9916, Val Loss=1.2906, Val Acc=0.7469\n",
      "Epoch 42: Train Loss=0.0155, Train Acc=0.9942, Val Loss=1.4941, Val Acc=0.7573\n",
      "Epoch 43: Train Loss=0.0245, Train Acc=0.9911, Val Loss=1.4029, Val Acc=0.7573\n",
      "Epoch 44: Train Loss=0.0237, Train Acc=0.9921, Val Loss=1.5450, Val Acc=0.7552\n",
      "Epoch 45: Train Loss=0.0109, Train Acc=0.9963, Val Loss=1.6878, Val Acc=0.7510\n",
      "Epoch 46: Train Loss=0.0230, Train Acc=0.9916, Val Loss=1.6871, Val Acc=0.7490\n",
      "Epoch 47: Train Loss=0.0171, Train Acc=0.9948, Val Loss=1.6609, Val Acc=0.7469\n",
      "Epoch 48: Train Loss=0.0280, Train Acc=0.9948, Val Loss=1.4530, Val Acc=0.7448\n",
      "Epoch 49: Train Loss=0.0143, Train Acc=0.9948, Val Loss=1.5477, Val Acc=0.7531\n",
      "Epoch 50: Train Loss=0.0161, Train Acc=0.9948, Val Loss=1.5465, Val Acc=0.7531\n",
      "Epoch 51: Train Loss=0.0257, Train Acc=0.9906, Val Loss=1.5710, Val Acc=0.7406\n",
      "Epoch 52: Train Loss=0.0261, Train Acc=0.9880, Val Loss=1.4818, Val Acc=0.7531\n",
      "Epoch 53: Train Loss=0.0206, Train Acc=0.9927, Val Loss=1.4335, Val Acc=0.7448\n",
      "Epoch 54: Train Loss=0.0215, Train Acc=0.9927, Val Loss=1.4867, Val Acc=0.7531\n",
      "Epoch 55: Train Loss=0.0188, Train Acc=0.9948, Val Loss=1.3992, Val Acc=0.7573\n",
      "Epoch 56: Train Loss=0.0197, Train Acc=0.9942, Val Loss=1.5135, Val Acc=0.7594\n",
      "Epoch 57: Train Loss=0.0134, Train Acc=0.9953, Val Loss=1.6627, Val Acc=0.7615\n",
      "Epoch 58: Train Loss=0.0117, Train Acc=0.9963, Val Loss=1.7010, Val Acc=0.7469\n",
      "Epoch 59: Train Loss=0.0150, Train Acc=0.9927, Val Loss=1.7050, Val Acc=0.7552\n",
      "Epoch 60: Train Loss=0.0292, Train Acc=0.9890, Val Loss=1.5168, Val Acc=0.7594\n",
      "Epoch 61: Train Loss=0.0313, Train Acc=0.9890, Val Loss=1.3479, Val Acc=0.7594\n",
      "Epoch 62: Train Loss=0.0274, Train Acc=0.9895, Val Loss=1.2829, Val Acc=0.7720\n",
      "Early stopping triggered after 62 epochs.\n"
     ]
    }
   ],
   "source": [
    "best_train_loss, best_train_acc, best_val_loss, best_val_acc = best_model.es_train(train_loader=train_loader, val_loader=val_loader,\n",
    "                    es_patience=50, # epochs without improvement\n",
    "                    max_epochs=1000, # cap for epochs\n",
    "                    verbose=True, # print training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04978b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8538, Validation accuracy: 0.7688\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c287db",
   "metadata": {},
   "source": [
    "Now it can be used as a regular nn.Module model, as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = best_model.to(device)\n",
    "best_model.eval()\n",
    "X_test_tensor = X_test.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = best_model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted_classes = torch.max(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a09f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
